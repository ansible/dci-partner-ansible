---
# Initial Step:
#
# Schedule a new job giving a specific topic and specifying the remote CI.
# The return of this action contains all the data associated with the job,
# we hence register those data for later consumptions
#
# Retrieves all of the information about a specific topic from the control
# server.

- hosts: localhost
  tasks:
    - name: Schedule a new job
      dci_job:
        topic: '{{ topic }}'
        remoteci: '{{ platform }}'
      register: job_informations


# New state
#
# User is free to do whaterver she needs before entering pre-run state.
#
# The test state on the control server is updated by setting the dci_status
# variable
#

- name: Retrieve, install and configure the components
  hosts: localhost
  vars:
    # The status is updated on the control server by setting the dci_status
    # variable
    dci_status: 'new'
    components: "{{ job_informations['components'] }}"
  tasks:
    - block:
        # We ensure the platform against which we will run our test
        # is always clean
        - include: hooks/teardown.yml
        # This checks to see if the code for the most recent snapshot of the
        # topic has already been pulled. If it hasn't, it pulls the code
        # and saves it onto the agent somewhere.
        - include: hooks/new.yml

      rescue:
        # Should any of these steps fail, teardown the test environment and
        # report failure.
        - include: hooks/teardown.yml
        # Our failue script is configured to post a notification to one of our
        # slack channels
        - include: hooks/failure.yml


# Pre-run state
#
# User is free to do whaterver she needs before entering pre-run state.
#
- name: Spawn the testrunner VM that will be reaching the environment to tests
  hosts: localhost
  vars:
    dci_status: 'pre-run'
  tasks:
    - block:
        # This is where you would provision a new VM for running tests on.
        # We are using Node Pool which automatically rebuilds a new VM after the
        # old is deleted, so in our case the new VM is actually provisioned in
        # the teardown step, and our pre-run.yml doesn't actually do anything.
        - include: hooks/pre-run.yml
      rescue:
        - include: hooks/teardown.yml
        - include: hooks/failure.yml


# Running state
#
# User is free to do whaterver she needs in the running state.
#
- name: Provision the environment to test with the correct version of Ansible
  hosts: testrunner
  vars:
    dci_status: 'running'
    agent_public_ip: '{{ hostvars.localhost.agent_public_ip }}'
    ansible_commit: '{{ hostvars.localhost.ansible_commit }}'
  tasks:
    - block:
        # Ensures that any previous versions of ansible are removed and copies
        # the new version from hooks/new.yml over to the nodepool server.
        - include: hooks/running.yml

      rescue:
        - include: hooks/teardown.yml
        - include: hooks/failure.yml


# Post-run state
#
# User is free to do whaterver she needs before entering post-run state.
# Usually this is used to run tests
#
- name: Run the integration tests and retrieve the junit results
  hosts: testrunner
  vars:
    dci_status: 'post-run'
    job_id: "{{ hostvars.localhost.job_informations['job_id'] }}"
  tasks:
    - block:
        # This is where the actual integration tests are run. We set up the
        # ansible environment by running source ansible/hacking/env-setup. Then
        # the tests are run by running the playbook for testing the device.
        # Junit results are collected and uploaded to the control server.
        - include: hooks/post-run.yml

      rescue:
        - include: hooks/teardown.yml
        - include: hooks/failure.yml


# Success state
#
# User is free to do whaterver she needs before entering success state.
# Usually this is used to teardown the plateform
#
- name: Celebrate the success
  hosts: localhost
  vars:
    dci_status: 'success'
  tasks:
    - block:
        - include: hooks/success.yml
        - include: hooks/teardown.yml
